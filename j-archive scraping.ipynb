{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import csv\n",
    "import nltk \n",
    "import numpy as np\n",
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creates state list from csv file.   \n",
    "\n",
    "with open(\"States_population.csv\",\"r\",encoding=\"utf-8\") as file:\n",
    "    csv_file = csv.reader(file)\n",
    "    state_pop={}\n",
    "    for row in csv_file:\n",
    "        \n",
    "        \n",
    "        #clean and create dictionary with format {state,population}\n",
    "        state = str(row[0]).replace(\"\\xa0\",\"\").replace(\"\\ufeff\",\"\")\n",
    "        #remove commas from population\n",
    "        population = str(row[1]).replace(\",\",\"\")\n",
    "        state_pop[state] = population\n",
    "        \n",
    "\n",
    "#create state list \n",
    "state_list = list(state_pop.keys())\n",
    "state_list.pop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This pulled all answers from the j-archive and created text file in form answer------year\n",
    "\n",
    "#create list of all seasons (38 seasons total)\n",
    "years = list(range(1,39))\n",
    "\n",
    "#for each season, request the seasons main page and create list (cleaned_links) for each individual episode\n",
    "for year in years:\n",
    "    url = f\"https://www.j-archive.com/showseason.php?season={year}\"\n",
    "    r = requests.get(url)   \n",
    "    soup = BeautifulSoup(r.text, \"xml\")\n",
    "    raw_links=[]\n",
    "    cleaned_links = []\n",
    "    \n",
    "    #find all links\n",
    "    for link in soup.find_all(\"a\"):\n",
    "        raw_links.append(link.get('href'))\n",
    "        \n",
    "    #filter to only include episode links. add to cleaned_links   \n",
    "    for link in raw_links:\n",
    "        if \"https://www.j-archive.com/showgame\" in link:\n",
    "            cleaned_links.append(link)\n",
    "            \n",
    "    #for each episode (cleaned_links),  find all answers through regex        \n",
    "    for link in cleaned_links:\n",
    "        url=link\n",
    "        r = requests.get(url)\n",
    "        soup = BeautifulSoup(r.text, \"xml\")\n",
    "        s = str(soup.prettify)\n",
    "        \n",
    "        #regex \n",
    "        comp=re.compile(\"correct_response&quot;&gt;[^&]+\")\n",
    "        raw_answer=comp.findall(s)\n",
    "        \n",
    "        \n",
    "        #clean answer and insert into text file with format (answer------year)\n",
    "        for answer in raw_answer:\n",
    "            full_answer = answer.replace(\"correct_response&quot;&gt;\",\"\")\n",
    "            with open(\"j_archive_full_answers.txt\",\"a\",encoding='utf-8') as f:\n",
    "                f.write(full_answer + \"\\t\" + str(year))\n",
    "                f.write(\"\\n\")\n",
    "                \n",
    "            \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open text file of answers and create list with all answers\n",
    "answer_list = []\n",
    "with open(\"j_archive_full_answers.txt\",\"r\",encoding='utf-8') as j:\n",
    "    for row in j:\n",
    "        row = row.split(\"\\t\")\n",
    "        answer_list.append(row[0])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creates frequency distributions input: answer_list output: frequency distributions\n",
    "# full_list_no_exact(_fd) = answers with a state name in them but not the actual state\n",
    "# full_list(_fd) = all answers with the state name in it\n",
    "# exact_list(_fd) = Only exact matches to the actual state\n",
    "\n",
    "full_list_no_exact = []\n",
    "full_list = []\n",
    "#frequency distribution of all state name mentions\n",
    "for item in answer_list:\n",
    "    for state in state_list:\n",
    "        if state in item:\n",
    "            full_list.append(item)\n",
    "full_list_fd = FreqDist(full_list)\n",
    "#frequency distribution of exact matches to state names           \n",
    "exact_list = []\n",
    "for a in full_list:\n",
    "    if a in state_list:\n",
    "        exact_list.append(a)\n",
    "exact_list_fd = FreqDist(exact_list)\n",
    "\n",
    "#frequency distribution of state names that aren't exact matches        \n",
    "for item in full_list:\n",
    "    if item not in exact_list:\n",
    "        full_list_no_exact.append(item)\n",
    "        \n",
    "full_list_no_exact_fd = FreqDist(full_list_no_exact)        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear contents of state frequency distribution text.\n",
    "with open(\"state_frequency_distribution.txt\",\"r+\",encoding = \"utf-8\") as file:\n",
    "    file.truncate(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#state_pop[state] = population\n",
    "#f.write(full_answer + \"\\t\" + str(year))\n",
    "#state_list\n",
    "for state in exact_list_fd:\n",
    "    answer_count = exact_list_fd[state]\n",
    "    population = int(state_pop[state])\n",
    "    #create ratio of answers per 1 million people\n",
    "    answers_per = round(((answer_count/population) * 1000000),2)\n",
    "    with open(\"state_frequency_distribution.txt\",\"a\",encoding = \"utf-8\") as state_file:\n",
    "        state_file.write(state + \"\\t\" + str(answer_count) + \"\\t\" + str(population) + \"\\t\" + str(answers_per)+ \"\\n\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#included statistics\n",
    "#total answers\n",
    "print(len(answer_list))\n",
    "#unique answers\n",
    "print(len(set(answer_list)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# frequency distribution of full_answer_list\n",
    "full_answer_fd = FreqDist(answer_list)\n",
    "\n",
    "#50 most common Jeopardy answers\n",
    "full_answer_fd.most_common(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
